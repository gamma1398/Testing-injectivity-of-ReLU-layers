{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10528\\167960093.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-setosa\",0.0)\n",
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10528\\167960093.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-versicolor\",1.0)\n",
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10528\\167960093.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-virginica\",2.0)\n",
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10528\\167960093.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-virginica\",2.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import torch.nn as nn     \n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import main\n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "y[\"class\"]=y[\"class\"].replace(\"Iris-setosa\",0.0)\n",
    "y[\"class\"]=y[\"class\"].replace(\"Iris-versicolor\",1.0)\n",
    "y[\"class\"]=y[\"class\"].replace(\"Iris-virginica\",2.0)\n",
    "# metadata \n",
    "X=X.values\n",
    "y=y.values\n",
    "y=y.squeeze(axis=1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "mean = X_train.mean(axis=0)  # Mean of training set\n",
    "std = X_train.std(axis=0)  # Standard deviation of training set\n",
    "\n",
    "# Avoid division by zero for constant features\n",
    "std[std == 0] = 1\n",
    "\n",
    "# Apply mean normalization (centering and scaling) to training and test sets\n",
    "X_train_numpy = (X_train - mean) / std\n",
    "X_test_numpy = (X_test - mean) / std\n",
    "\n",
    "X_train=torch.FloatTensor(X_train_numpy)\n",
    "X_test=torch.FloatTensor(X_test_numpy)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Version one with hard thresholding\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=4,h1=16,out=3):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(in_features,h1,bias=False)\n",
    "        self.out=nn.Linear(h1,out)\n",
    "    def forward(self,x):\n",
    "        hidden_activation = F.relu(self.fc1(x))  # Hidden layer with ReLU activation\n",
    "        output = self.out(hidden_activation)  # Final output\n",
    "        return output, hidden_activation\n",
    "def iris_training(h1,alpha):\n",
    "    model=Model(h1=h1)\n",
    "    W_untrained=copy.deepcopy(next(model.parameters())).detach().numpy().astype(float)\n",
    "    #print(W_untrained)\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    epochs=100\n",
    "    losses=[]\n",
    "    for i in range(epochs):\n",
    "        y_pred,hidden_activation=model.forward(X_train)\n",
    "        classification_loss=loss=criterion(y_pred,y_train)\n",
    "        neuron_activity_loss = -torch.mean(F.relu(hidden_activation))\n",
    "        loss=classification_loss+alpha*neuron_activity_loss\n",
    "        losses.append(classification_loss.detach().numpy())\n",
    "        #if i % 10 == 0:\n",
    "           # print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    W_trained=next(model.parameters()).detach().numpy().astype(float)\n",
    "    return W_untrained,W_trained,classification_loss.detach().numpy()\n",
    "#plt.plot(range(epochs),losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 14\n",
      "train loss= 0.161274254322052 \n",
      "m=14 untrained= 10,trained = 4\n",
      "start 15\n",
      "train loss= 0.1593208909034729 \n",
      "m=15 untrained= 62,trained = 16\n",
      "start 16\n",
      "train loss= 0.15589338541030884 \n",
      "m=16 untrained= 110,trained = 48\n",
      "start 17\n",
      "train loss= 0.15490448474884033 \n",
      "m=17 untrained= 210,trained = 102\n",
      "start 18\n",
      "train loss= 0.15356218814849854 \n",
      "m=18 untrained= 308,trained = 162\n",
      "start 19\n",
      "train loss= 0.15076622366905212 \n",
      "m=19 untrained= 490,trained = 286\n",
      "start 20\n",
      "train loss= 0.15090371668338776 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Cplex.__del__ at 0x0000025F450970A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cplex\\__init__.py\", line 925, in __del__\n",
      "    self.end()\n",
      "  File \"c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cplex\\__init__.py\", line 921, in end\n",
      "    self._env._end()\n",
      "  File \"c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cplex\\_internal\\__init__.py\", line 153, in _end\n",
      "    self._delete_stream(chnl_idx)\n",
      "  File \"c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cplex\\_internal\\__init__.py\", line 248, in _delete_stream\n",
      "    self._streams[which_channel]._end()\n",
      "  File \"c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cplex\\_internal\\_ostream.py\", line 88, in _end\n",
      "    self.flush()\n",
      "  File \"c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cplex\\_internal\\_ostream.py\", line 148, in flush\n",
      "    self._file.flush()\n",
      "  File \"C:\\Users\\Sebas\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\iostream.py\", line 475, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"C:\\Users\\Sebas\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\iostream.py\", line 210, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"C:\\Users\\Sebas\\AppData\\Roaming\\Python\\Python310\\site-packages\\zmq\\sugar\\socket.py\", line 620, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 746, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 793, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 250, in zmq.backend.cython.socket._send_copy\n",
      "  File \"zmq\\backend\\cython\\checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "total_untrained=[]\n",
    "total_trained=[]\n",
    "total_losses=[]\n",
    "total_train_losses=[]\n",
    "total_test_losses=[]\n",
    "for m in range(14,35):\n",
    "    print(f\"start {m}\")\n",
    "    train_losses=[]\n",
    "    untrained=[]\n",
    "    trained=[]\n",
    "    for i in range(500):\n",
    "        res=iris_training(m,0)\n",
    "        untrained.append(res[0])\n",
    "        trained.append(res[1])\n",
    "        train_losses.append(res[2])\n",
    "\n",
    "    train_losses=np.array(train_losses)\n",
    "\n",
    "    total_train_losses.append(np.mean(train_losses))\n",
    "\n",
    "    print(f\"train loss= {np.mean(train_losses)} \")\n",
    "    res=0\n",
    "\n",
    "\n",
    "    for W in untrained:\n",
    "    # print(W.T.shape)\n",
    "        if not main.findCell(np.array([]),W):\n",
    "            res+=2\n",
    "\n",
    "    train=0\n",
    "\n",
    "    for W in trained:\n",
    "\n",
    "        non_inj_count=0\n",
    "        if not main.findCell(np.array([]), W):\n",
    "            train+=2\n",
    "\n",
    "\n",
    "   \n",
    "    total_untrained.append(res)\n",
    "    total_trained.append(train)\n",
    "\n",
    "    print(f\"m={m} untrained= {res},trained = {train}\" )\n",
    "print(total_untrained,total_trained,total_train_losses,total_test_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sebas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17846596\n",
      "m=14 untrained= 6,trained = 0\n",
      "start 15\n",
      "0.17654671\n",
      "m=15 untrained= 50,trained = 2\n",
      "start 16\n",
      "0.17436498\n",
      "m=16 untrained= 124,trained = 14\n",
      "start 17\n",
      "0.17363718\n",
      "m=17 untrained= 228,trained = 20\n",
      "start 18\n",
      "0.17162469\n",
      "m=18 untrained= 382,trained = 48\n",
      "start 19\n",
      "0.17055106\n",
      "m=19 untrained= 466,trained = 60\n",
      "start 20\n",
      "0.16940644\n",
      "m=20 untrained= 608,trained = 116\n",
      "start 21\n",
      "0.16765751\n",
      "m=21 untrained= 668,trained = 150\n",
      "start 22\n",
      "0.16799492\n",
      "m=22 untrained= 752,trained = 174\n",
      "start 23\n",
      "0.16624339\n",
      "m=23 untrained= 820,trained = 244\n",
      "start 24\n",
      "0.16547903\n",
      "m=24 untrained= 872,trained = 320\n",
      "start 25\n",
      "0.16449836\n",
      "m=25 untrained= 910,trained = 384\n",
      "start 26\n",
      "0.16381554\n",
      "m=26 untrained= 958,trained = 412\n",
      "start 27\n",
      "0.16302942\n",
      "m=27 untrained= 956,trained = 522\n",
      "start 28\n",
      "0.16228731\n",
      "m=28 untrained= 970,trained = 580\n",
      "start 29\n",
      "0.16141848\n",
      "m=29 untrained= 982,trained = 610\n",
      "start 30\n",
      "0.1607486\n",
      "m=30 untrained= 978,trained = 660\n",
      "start 31\n",
      "0.16008154\n",
      "m=31 untrained= 992,trained = 722\n",
      "start 32\n",
      "0.15940036\n",
      "m=32 untrained= 992,trained = 784\n",
      "start 33\n",
      "0.15835297\n",
      "m=33 untrained= 996,trained = 792\n",
      "start 34\n",
      "0.1578209\n",
      "m=34 untrained= 996,trained = 848\n"
     ]
    }
   ],
   "source": [
    "for m in range(14,35):\n",
    "    print(f\"start {m}\")\n",
    "    losses=[]\n",
    "    untrained=[]\n",
    "    trained=[]\n",
    "    for i in range(500):\n",
    "        res=iris_training(m,-0.1)\n",
    "        losses.append(res[2])\n",
    "        untrained.append(res[0])\n",
    "        trained.append(res[1])\n",
    "    losses=np.array(losses)\n",
    "    print(np.mean(losses))\n",
    "    res=0\n",
    "    for W in untrained:\n",
    "    # print(W.T.shape)\n",
    "        if not main.findCell(np.array([]),W):\n",
    "            res+=2\n",
    "    res\n",
    "    train=0\n",
    "    for W in trained:\n",
    "        if not main.findCell(np.array([]), W):\n",
    "            train+=2\n",
    "    print(f\"m={m} untrained= {res},trained = {train}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
