{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10812\\167960093.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-setosa\",0.0)\n",
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10812\\167960093.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-versicolor\",1.0)\n",
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10812\\167960093.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-virginica\",2.0)\n",
      "C:\\Users\\Sebas\\AppData\\Local\\Temp\\ipykernel_10812\\167960093.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[\"class\"]=y[\"class\"].replace(\"Iris-virginica\",2.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import torch.nn as nn     \n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import main\n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "y[\"class\"]=y[\"class\"].replace(\"Iris-setosa\",0.0)\n",
    "y[\"class\"]=y[\"class\"].replace(\"Iris-versicolor\",1.0)\n",
    "y[\"class\"]=y[\"class\"].replace(\"Iris-virginica\",2.0)\n",
    "# metadata \n",
    "X=X.values\n",
    "y=y.values\n",
    "y=y.squeeze(axis=1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "mean = X_train.mean(axis=0)  # Mean of training set\n",
    "std = X_train.std(axis=0)  # Standard deviation of training set\n",
    "\n",
    "# Avoid division by zero for constant features\n",
    "std[std == 0] = 1\n",
    "\n",
    "# Apply mean normalization (centering and scaling) to training and test sets\n",
    "X_train_numpy = (X_train - mean) / std\n",
    "X_test_numpy = (X_test - mean) / std\n",
    "\n",
    "X_train=torch.FloatTensor(X_train_numpy)\n",
    "X_test=torch.FloatTensor(X_test_numpy)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Version one with hard thresholding\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=4,h1=16,out=3):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(in_features,h1,bias=False)\n",
    "        self.out=nn.Linear(h1,out)\n",
    "    def forward(self,x):\n",
    "        hidden_activation = F.relu(self.fc1(x))  # Hidden layer with ReLU activation\n",
    "        output = self.out(hidden_activation)  # Final output\n",
    "        return output, hidden_activation\n",
    "def iris_training(h1,alpha):\n",
    "    model=Model(h1=h1)\n",
    "    W_untrained=copy.deepcopy(next(model.parameters())).detach().numpy().astype(float)\n",
    "    #print(W_untrained)\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    epochs=100\n",
    "    losses=[]\n",
    "    for i in range(epochs):\n",
    "        y_pred,hidden_activation=model.forward(X_train)\n",
    "        classification_loss=loss=criterion(y_pred,y_train)\n",
    "        neuron_activity_loss = -torch.mean(F.relu(hidden_activation))\n",
    "        loss=classification_loss+alpha*neuron_activity_loss\n",
    "        losses.append(classification_loss.detach().numpy())\n",
    "        #if i % 10 == 0:\n",
    "           # print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    W_trained=next(model.parameters()).detach().numpy().astype(float)\n",
    "    return W_untrained,W_trained,classification_loss.detach().numpy()\n",
    "#plt.plot(range(epochs),losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 14\n",
      "0.18699163\n",
      "m=14 untrained= 10,trained = 6\n",
      "start 15\n",
      "0.1840094\n",
      "m=15 untrained= 38,trained = 44\n",
      "start 16\n",
      "0.18240489\n",
      "m=16 untrained= 106,trained = 108\n",
      "start 17\n",
      "0.17959549\n",
      "m=17 untrained= 176,trained = 188\n",
      "start 18\n",
      "0.17863674\n",
      "m=18 untrained= 332,trained = 334\n",
      "start 19\n",
      "0.17853501\n",
      "m=19 untrained= 472,trained = 410\n",
      "start 20\n",
      "0.17706366\n",
      "m=20 untrained= 566,trained = 540\n",
      "start 21\n",
      "0.17499143\n",
      "m=21 untrained= 700,trained = 636\n",
      "start 22\n",
      "0.17461213\n",
      "m=22 untrained= 728,trained = 688\n",
      "start 23\n",
      "0.17321113\n",
      "m=23 untrained= 818,trained = 766\n",
      "start 24\n",
      "0.17255086\n",
      "m=24 untrained= 882,trained = 842\n",
      "start 25\n",
      "0.17247441\n",
      "m=25 untrained= 926,trained = 904\n",
      "start 26\n",
      "0.17130975\n",
      "m=26 untrained= 942,trained = 950\n",
      "start 27\n",
      "0.17072603\n",
      "m=27 untrained= 946,trained = 904\n",
      "start 28\n",
      "0.17038335\n",
      "m=28 untrained= 978,trained = 956\n",
      "start 29\n",
      "0.16944845\n",
      "m=29 untrained= 976,trained = 962\n",
      "start 30\n",
      "0.16991886\n",
      "m=30 untrained= 994,trained = 970\n",
      "start 31\n",
      "0.16857992\n",
      "m=31 untrained= 996,trained = 986\n",
      "start 32\n",
      "0.16825998\n",
      "m=32 untrained= 996,trained = 982\n",
      "start 33\n",
      "0.16795859\n",
      "m=33 untrained= 1000,trained = 992\n",
      "start 34\n",
      "0.16771579\n",
      "m=34 untrained= 1000,trained = 998\n"
     ]
    }
   ],
   "source": [
    "for m in range(14,35):\n",
    "    print(f\"start {m}\")\n",
    "    losses=[]\n",
    "    untrained=[]\n",
    "    trained=[]\n",
    "    for i in range(500):\n",
    "        res=iris_training(m,0.5)\n",
    "        losses.append(res[2])\n",
    "        untrained.append(res[0])\n",
    "        trained.append(res[1])\n",
    "    losses=np.array(losses)\n",
    "    print(np.mean(losses))\n",
    "    res=0\n",
    "    for W in untrained:\n",
    "    # print(W.T.shape)\n",
    "        if not main.findCell(np.array([]),W):\n",
    "            res+=2\n",
    "    res\n",
    "    train=0\n",
    "    for W in trained:\n",
    "        if not main.findCell(np.array([]), W):\n",
    "            train+=2\n",
    "    print(f\"m={m} untrained= {res},trained = {train}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
